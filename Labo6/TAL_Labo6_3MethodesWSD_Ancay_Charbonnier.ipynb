{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 6\n",
    "# Trois méthodes de désambiguïsation lexicale\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "L'objectif de ce laboratoire est d'implémenter et de comparer plusieurs méthodes de désambiguïsation lexicale (en anglais, *Word Sense Disambiguation* ou WSD).  Vous utiliserez un corpus avec plusieurs milliers de phrases, chaque phrase contenant une occurrence du mot anglais *interest* annotée avec le sens que ce mot possède dans la phrase respective.  Les trois méthodes sont les suivantes (elles seront détaillées par la suite) :\n",
    "\n",
    "* Algorithme de Lesk simplifié.\n",
    "* Utilisation de word2vec.\n",
    "* Classification supervisée utilisant des traits lexicaux.\n",
    "\n",
    "Les deux premières méthodes n'utilisent pas l'apprentissage automatique.  Elles fonctionnent selon le même principe : comparer le contexte d'une occurrence de *interest* avec chacune des définitions des sens (*synsets*) et choisir la définition la plus proche du contexte.  L'algorithme de Lesk définit la proximité comme le nombre de mots en commun, alors que word2vec la calcule comme la similarité de vecteurs.  La dernière méthode vise à classifier les occurrences de *interest*, les sens étant les classes, et les attributs étant les mots du contexte (apprentissage supervisé)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse des données\n",
    "\n",
    "Téléchargez le corpus *interest* depuis le [site du Prof. Ted Pedersen](http://www.d.umn.edu/~tpederse/data.html) (il se trouve en bas de sa page web).  Téléchargez l'archive ZIP marquée *original format without POS tags* et extrayez le fichier `interest-original.txt`.  Téléchargez également le fichier `README.int.txt` indiqué à la ligne au-dessus. Veuillez répondre brièvement aux questions suivantes :\n",
    "\n",
    "a. Quelles sont les URL du fichier ZIP et celle du fichier `README.int.txt` ?\n",
    "\n",
    "b. Quel est le format du fichier `interest-original.txt` et comment sont annotés les sens de *interest* ?\n",
    "\n",
    "c. Est-ce qu'il y a aussi des occurrences au pluriel (*interests*) à traite ?\n",
    "\n",
    "d. Comment sont annotées les phrases qui contiennent plusieurs occurrences du mot *interest* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici (en commentaire) aux questions.\n",
    "\n",
    "# a. Les URL sont les suivantes :\n",
    "# https://www.d.umn.edu/~tpederse/Data/interest-original.nopos.tar.gz\n",
    "# https://www.d.umn.edu/~tpederse/Data/README.int.txt\n",
    "\n",
    "# b. Le format du fichier `interest-original.txt` est le suivant : chaque phrase est délimitée par des $$.\n",
    "# Aussi, chaque occurrence du mot *interest* est écrite avec le numéro de son sens. Par exemple, interest_6.\n",
    "\n",
    "# c. Oui, il y a aussi des occurrences au pluriel. Elles sont annotées de la même manière que les occurrences au singulier,\n",
    "# mais avec un \"s\" à la fin. Par exemple, interests_4.\n",
    "\n",
    "# d. Les phrases contienant plusieurs occurrences du mot *interest* ne sont annotées qu'une seule fois.\n",
    "\n",
    "# Par exemple, avec la phrase \"it  is n't *interested in mounting  ...  the growing interest_1  in  the british concern\"\n",
    "# on voit que le premier mot \"interested\" commence par un * qui indique qu'il ne s'agit pas de l'occurence du mot *interest*\n",
    "# qui nous intéresse. Il faut donc ignorer ce mot. De plus, le mot \"interest_1\" est annoté avec le numéro de son sens, ici 1.\n",
    "\n",
    "# La phrase est ensuite dupliquée en échangant l'intérêt pour les deux mots *interest*.\n",
    "# Celui qui était ignoré devient celui qui est annoté et l'autre est ignoré avec un *."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e.** D'après le fichier `README.int.txt`, quelles sont les définitions des six sens de *interest* annotés dans les données et quelles sont leurs fréquences ? Vous pouvez copier/coller l'extrait de `README`ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "# Sense 1 =  361 occurrences (15%) - readiness to give attention (En français : disposition à prêter attention)\n",
    "# Sense 2 =   11 occurrences (01%) - quality of causing attention to be given to (En français : qualité de provoquer l'attention)\n",
    "# Sense 3 =   66 occurrences (03%) - activity, etc. that one gives attention to (En français : activité, etc. à laquelle on prête attention)\n",
    "# Sense 4 =  178 occurrences (08%) - advantage, advancement or favor (En français : avantage, avancement ou faveur)\n",
    "# Sense 5 =  500 occurrences (21%) - a share in a company or business (En français : une part dans une société ou une entreprise)\n",
    "# Sense 6 = 1252 occurrences (53%) - money paid for the use of money (En français : argent payé pour l'utilisation de l'argent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1f.** De quel dictionnaire viennent les sens précédents ? Où peut-on le consulter en ligne ?  Veuillez aligner les définitions du dictionnaire avec les six sens annotés en écrivant par exemple `Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "# Les senses viennent de la version électronique de la première édition du Longman's Dictionary of Contemporary English.\n",
    "\n",
    "# Nous pouvons le consulter en ligne à l'adresse suivante : https://www.ldoceonline.com/\n",
    "\n",
    "# Sens 1 = \"if you have an interest in something or someone, you want to know or learn more about them\"\n",
    "# Sens 2 = \"a quality or feature of something that attracts your attention or makes you want to know more about it\"\n",
    "# Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"\n",
    "# Sens 4 = \"the things that bring advantages to someone or something\"\n",
    "# Sens 5 = \"if you have an interest in a particular company or industry, you own shares in it\"\n",
    "# Sens 6 = \"the extra money that you must pay back when you borrow money\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1g.** En consultant [WordNet en ligne](http://wordnetweb.princeton.edu/perl/webwn), trouvez les définitions des synsets  pour le **nom commun** *interest*.  Combien de synsets y a-t-il ?  Veuillez indiquer comme avant la **définition** de chaque synset pour chacun des six sens ci-dessus (au besoin, fusionner ou ignorer des synsets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "# Sens 1 = \"a sense of concern with and curiosity about someone or something\"\n",
    "# Sens 2 = \"the power of attracting or holding one's attention \"\n",
    "# Sense 3 = \"a social group whose members control some field of activity and who have common aims\"\n",
    "# Sens 4 = \"a reason for wanting something done in the common interest\"\n",
    "# Sens 5 = \"a right or legal share of something; a financial involvement with something\"\n",
    "# Sens 6 = \"a fixed charge for borrowing money; usually a percentage of the amount borrowed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1h.** Définissez (manuellement, ou avec quelques lignes de code) une liste nommée `senses1` avec les mots des définitions du README, en supprimant les stopwords (p.ex. les mots < 4 lettres).  Affichez la liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'readiness', 'give', 'attention'}, {'causing', 'attention', 'given', 'quality'}, {'attention', 'that', 'activity', 'gives'}, {'advancement', 'advantage', 'favor'}, {'company', 'business', 'share'}, {'paid', 'money'}]\n",
      "6\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Veuillez répondre ici à la question et créer la variable 'senses1' (liste de 6 listes de chaînes).\n",
    "senses1 = []\n",
    "\n",
    "readme_string = \"readiness to give attention\\nquality of causing attention to be given to\\nactivity etc that one gives attention to\\nadvantage advancement or favor\\na share in a company or business\\nmoney paid for the use of money\"\n",
    "\n",
    "\n",
    "for sentence in readme_string.split(\"\\n\"):\n",
    "    tokens = sentence.split(\" \")\n",
    "    senses = set([word for word in tokens if len(word) > 3])\n",
    "    senses1.append(senses)\n",
    "\n",
    "print(senses1)\n",
    "print(len(senses1))\n",
    "print(sum([len(sense) for sense in senses1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1i.** En combinant les définitions obtenues aux points (4) et (5) ci-dessus, construisez une liste nommée `senses2` avec pour chacun des sens de *interest* une liste de **mots-clés** correspondants.  Vous pouvez concaténer les définitions, puis écrire des instructions en Python pour extraire les mots (uniques).  Respectez l'ordre des sens données par `README`, et à la fin affichez `senses2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'with', 'want', 'learn', 'them', 'concern', 'someone,', 'know', 'sense', 'interest', 'about', 'something', 'curiosity', 'have', 'more', 'someone'}, {'makes', 'want', 'your', 'that', 'attracts', 'know', 'power', 'attracting', \"one's\", 'about', 'something', 'quality', 'more', 'attention', 'feature', 'holding'}, {'whose', 'activity', 'subject', 'social', 'group', 'common', 'enjoy', 'that', 'studying', 'doing', 'field', 'aims', 'have', 'members', 'some', 'control'}, {'reason', 'things', 'wanting', 'common', 'that', 'bring', 'interest', 'done', 'something', 'advantages', 'someone'}, {'with', 'legal', 'involvement', 'share', 'right', 'company', 'something;', 'interest', 'particular', 'financial', 'something', 'have', 'shares', 'industry,'}, {'fixed', 'borrow', 'borrowed', 'that', 'must', 'when', 'money;', 'amount', 'usually', 'back', 'borrowing', 'extra', 'money', 'charge', 'percentage'}]\n",
      "6\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# Veuillez répondre ici à la question et créer la variable 'senses2' (liste de 6 listes de chaînes).\n",
    "senses2 = []\n",
    "\n",
    "string_f = \"if you have an interest in something or someone, you want to know or learn more about them\\na quality or feature of something that attracts your attention or makes you want to know more about it\\nan activity that you enjoy doing or a subject that you enjoy studying\\nthe things that bring advantages to someone or something\\nif you have an interest in a particular company or industry, you own shares in it\\nthe extra money that you must pay back when you borrow money\"\n",
    "\n",
    "string_g = \"a sense of concern with and curiosity about someone or something\\nthe power of attracting or holding one's attention\\na social group whose members control some field of activity and who have common aims\\na reason for wanting something done in the common interest\\na right or legal share of something; a financial involvement with something\\na fixed charge for borrowing money; usually a percentage of the amount borrowed\"\n",
    "\n",
    "string_f_split = string_f.split(\"\\n\")\n",
    "string_g_split = string_g.split(\"\\n\")\n",
    "\n",
    "for i in range(len(string_f_split)):\n",
    "    tokens_f = string_f_split[i].split(\" \")\n",
    "    tokens_g = string_g_split[i].split(\" \")\n",
    "    tokens = tokens_f + tokens_g\n",
    "    senses = set([word for word in tokens if len(word) > 3])\n",
    "    senses2.append(senses)\n",
    "\n",
    "print(senses2)\n",
    "print(len(senses2))\n",
    "print(sum([len(sense) for sense in senses2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1j.** Chargez les données depuis `interest-original.txt` dans une liste appelée `sentences` qui contient pour chaque phrase la liste des mots (sans les séparateurs *$$* et *===...*).  Ces phrases sont-elles déjà tokenisées en mots ?  Sinon, faites-le.  À ce stade, ne modifiez pas encore les occurrences annotées *interest(s)\\_X*.  Comptez le nombre total de phrases et affichez-en trois au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2368 phrases.\n",
      "En voici 3 au hasard :\n",
      "[['investor', 'interest_1', 'in', 'stock', 'funds', '``', 'has', \"n't\", 'stalled', 'at', 'all', ',', \"''\", 'mr.', 'hines', 'maintains', '.'], [\"''\", 'it', 'is', 'in', 'the', 'western', 'interest_4', 'to', 'see', 'mr.', 'gorbachev', 'succeed', '.'], ['revco', 'insists', 'that', 'the', 'proposal', 'is', 'simply', 'an', '``', 'expression', 'of', 'interest_1', ',', \"''\", 'because', 'under', 'chapter', '11', 'revco', 'has', '``', 'exclusivity', 'rights', \"''\", 'until', 'feb.', '28', '.']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Veuillez répondre ici à la question.\n",
    "sentences = []\n",
    "\n",
    "with open(\"data/interest-original.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Séparer les phrases sur \"$$\"\n",
    "raw_sentences = text.split(\"$$\")\n",
    "\n",
    "sentences = []\n",
    "for raw in raw_sentences:\n",
    "    # Nettoyer les sauts de ligne et espaces inutiles\n",
    "    cleaned = raw.strip()\n",
    "    if not cleaned:\n",
    "        continue\n",
    "\n",
    "    # Supprimer toute séquence \"====...====\", peu importe où elle apparaît\n",
    "    cleaned = re.sub(r\"={5,}.*?={5,}\", \"\", cleaned)\n",
    "\n",
    "    # Re-nettoyer les espaces et tokeniser\n",
    "    tokens = cleaned.strip().split()\n",
    "    if tokens:\n",
    "        sentences.append(tokens)\n",
    "\n",
    "\n",
    "print(\"Il y a {} phrases.\\nEn voici 3 au hasard :\".format(len(sentences)))\n",
    "print(sentences[151:154])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithme de Lesk simplifié\n",
    "\n",
    "**2a.** Définissez une fonction `wsd_lesk(senses, sentence)` qui prend deux arguments : une liste de listes de mots-clés (comme `senses1` et `senses2` ci-dessus) et une phrase avec une occurrence annotée de *interest* ou *interests*, et qui retourne l'index du sens le plus probable (entre 1 et 6) selon l'algorithme de Lesk.  Cet algorithme choisit le sens qui a le maximum de mots en commun avec le contexte de *interest*.  Vous pouvez choisir vous-mêmes la taille de ce voisinage (`window_size`).  En cas d'égalité entre deux sens, tirer la réponse au sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Définissez maintenant une fonction `evaluate_wsd(fct_name, senses, sentences)` qui prend en paramètre le nom de la méthode de similarité (pour commencer : `wsd_lesk`) ainsi que la liste des mots-clés par sens, et la liste de phrases, et qui retourne le score de la méthode de similarité.  Ce score sera tout simplement le pourcentage de réponses correctes (sens trouvé identique au sens annoté)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En fixant au mieux la taille de la fenêtre autour de *interest*, quel est le meilleur score de la méthode de Lesk simplifiée ?  Quelle liste de sens conduit à de meilleurs scores, `senses1` ou `senses2` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilisation de word2vec pour la similarité contexte vs. synset\n",
    "\n",
    "**3a.** En réutilisant une partie du code de `wsd_lesk`, veuillez maintenant définir une fonction `wsd_word2vec(senses, sentence)` qui choisit le sens en utilisant la similarité **word2vec** étudiée dans le labo précédent. \n",
    "* Vous pouvez chercher dans la [documentation des KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) comment calculer directement la similarité entre deux listes de mots.\n",
    "* Comme `wsd_lesk`, la nouvelle fonction `wsd_word2vec` prend en argument une liste de listes de mots-clés par sens (comme `senses1` et `senses2` ci-dessus), et une phrase avec une occurrence annotée de *interest* ou *interests*.\n",
    "* La fonction retourne le numéro du sens le plus probable selon la similarité word2vec entre les mots du sens et ceux du voisinage de *interest*.  En cas d'égalité, tirer le sens au sort.\n",
    "* Vous pouvez régler la taille du voisinage (`window_size`) par l'expérimentation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "path_to_model = \"../../../gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\" # à adapter\n",
    "wv_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_model, binary=True)  # C bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Appliquez maintenant la même méthode `evaluate_wsd` avec la fonction `wsd_word2vec` (en cherchant une bonne valeur de la taille de la fenêtre) et affichez le score de la similarité word2vec.  Comment se compare-t-il avec le score précédent (Lesk) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification supervisée avec des traits lexicaux\n",
    "Vous entraînerez maintenant des classifieurs pour prédire le sens d'une occurrence dans une phrase.  Le premier but sera de transformer chaque phrase en un ensemble d'attributs pour formater les données en vue des expériences de classification.\n",
    "\n",
    "Veuillez utiliser le classifieur `NaiveBayesClassifier` fourni par NLTK.  Le mode d'emploi se trouve dans le [Chapitre 6, sections 1.1-1.3](https://www.nltk.org/book/ch06.html) du livre NLTK.  Consultez-le attentivement pour trouver comment formater les données.  De plus, il faudra séparer les données en sous-ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vous propose de nommer les attributs `word-k`, ..., `word-2`, `word-1`, `word+1`, `word+2`, ..., `word+k` (fenêtre de taille `2*k` autour de *interest*).  Leurs valeurs sont les mots observés aux emplacements respectifs, ou `NONE` si la position dépasse l'étendue de la phrase.  Vous ajouterez un attribut nommé `word0` qui est l'occurrence du mot *interest* au singulier ou au pluriel.  \n",
    "\n",
    "Pour chaque occurrence de *interest*, vous devrez donc créer la représentation suivante (où `6` est le numéro du sens, essentiel pour l'entraînement, mais à cacher lors de l'évaluation) :\n",
    "```\n",
    "[{'word-1': 'in', 'word+1': 'rates', 'word-2': 'declines', 'word+2': 'NONE', 'word0': 'interest'}, 6]\n",
    "```\n",
    "\n",
    "**4a.** En partant de la liste des phrases appelée `sentences` préparée plus haut, veuillez générer la liste avec toutes les représentation, appelée `items_with_features`.  Vous pouvez vous aider du livre NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "print(len(items_with_features))\n",
    "print(items_with_features[151:154])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.** Veuillez séparer les données aléatoirement en 80% pour l'entraînement et 20%  pour l'évaluation.  Veuillez faire une division stratifiée : les deux sous-ensembles doivent contenir les mêmes proportions de sens que l'ensemble de départ.  Ils seront appelés `iwf_train` et `iwf_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_train = []\n",
    "iwf_test  = []\n",
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "print(len(iwf_train), ' ', len(iwf_test))\n",
    "print(iwf_test[:2], iwf_test[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez créer une instance de `NaiveBayesClassifier`, l'entraîner sur `iwf_train` et la tester sur `iwf_test` (voir la documentation NLTK).  En expérimentant avec différentes largeurs de fenêtres, quel est le meilleur score que vous obtenez (avec la fonction `accuracy` de NLTK) sur l'ensemble de test ?  Comment se compare-t-il avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import naivebayes \n",
    "# Veuillez répondre ici à la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** En utilisant la fonction `show_most_informative_features()`, veuillez afficher les attributs les plus informatifs et commenter le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e.** On souhaite également obtenir les scores pour chaque sens.  Pour ce faire, il faut demander les prédictions une par une au classifieur (voir le [livre NLTK](https://www.nltk.org/book/ch06.html)), et comptabiliser les prédictions correctes pour chaque sens.  Vous pouvez vous inspirer de `evaluate_wsd`, et écrire une fonction `evaluate_wsd_supervised(classifier, items_with_features)`, que vous appliquerez aux donnés `iwf_test`.  Veuillez afficher ces scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wsd_supervised(classifier, items_with_features):\n",
    "# à compléter\n",
    "\n",
    "evaluate_wsd_supervised(classifier, iwf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Veuillez recopier ci-dessous, en guise de conclusion, les scores des trois expériences réalisées, pour pouvoir les comparer d'un coup d'oeil.  Quel est le meilleur score obtenu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire\n",
    "\n",
    "Merci de nettoyer votre feuille, sauvegarder le résultat, et soumettre le *notebook* sur Cyberlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
