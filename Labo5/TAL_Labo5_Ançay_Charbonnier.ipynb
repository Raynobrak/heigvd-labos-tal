{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 5<br/> Word2Vec\n",
    "\n",
    "## Rémi Ançay - Lucas Charbonnier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tester et évaluer un modèle déjà entraîné sur Google News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader as api\n",
    "\n",
    "# Save the word2vec model to a file\n",
    "#w2v_vectors = api.load(\"word2vec-google-news-300\")\n",
    "#w2v_vectors.save_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors \n",
    "# Load the word2vec model from the file\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.  Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :* \n",
    "Pour cela, il faut d'abord exécuter la cellule ci-dessous pour charger le modèle. Ensuite, on peut regarder grâce au gestionnaire de tâches de l'OS combien de place il occupe. On voit que le modèle pèse environ 4 Go de mémoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.  Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de l'espace vectoriel :  300\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension de l'espace vectoriel : \", w2v_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.  Quelle est la taille du vocabulaire connu du modèle ?  Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire: 3000000\n",
      "Quelques mots anglais dans le vocabulaire :  ['was', 'the', 'at', 'not', 'as']\n",
      "\n",
      "Test de mots dans le vocabulaire : \n",
      "False False\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille du vocabulaire:\", len(w2v_vectors.key_to_index))\n",
    "\n",
    "print(\"Quelques mots anglais dans le vocabulaire : \", list(w2v_vectors.key_to_index.keys())[10:15])\n",
    "\n",
    "print(\"\\nTest de mots dans le vocabulaire : \")\n",
    "print(\"absquatulate\" in w2v_vectors, \"kakorrhaphiophobia\" in w2v_vectors)\n",
    "print(\"Lucas\" in w2v_vectors, \"Rémi\" in w2v_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "On peut voir ici que les mots \"absquatulate\" et \"kakorrhaphiophobia\" ne sont pas dans le vocabulaire du modèle. En revanche, les mots \"Lucas\", \"Rémi\" y sont présents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.  Quelle est la similarité entre les mots rabbit et carrot ?  Veuillez rappeler comment on mesure les \n",
    "similarités entre deux mots grâce à leurs vecteurs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre rabbit et carrot est :  0.36306432\n",
      "\n",
      "La similarité entre rabbit et cat est :  0.6261382\n"
     ]
    }
   ],
   "source": [
    "s1 = w2v_vectors.similarity(\"rabbit\", \"carrot\")\n",
    "print(\"\\nLa similarité entre rabbit et carrot est : \", s1)\n",
    "\n",
    "s2 = w2v_vectors.similarity(\"rabbit\", \"cat\")\n",
    "print(\"\\nLa similarité entre rabbit et cat est : \", s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "La similarité est mesurée grâce à la distance cosinus entre les deux vecteurs. On peut voir que la similarité entre \"rabbit\" et \"carrot\" est de 0.36. Cela signifie que ces deux mots sont assez proches l'un de l'autre dans l'espace vectoriel, mais pas trop. Par exemple entre \"rabbit\" et \"cat\", la similarité est de 0.62. Cela signifie que ces deux mots sont plus proches l'un de l'autre que \"rabbit\" et \"carrot\".\n",
    "\n",
    "La distance cosinus est calculée avec la formule suivante :\n",
    "$$\n",
    "\\text{similarity}(a, b) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}$$\n",
    "où $a$ et $b$ sont les vecteurs de mots, $||a||$ et $||b||$ sont les normes des vecteurs, et $a \\cdot b$ est le produit scalaire entre les deux vecteurs.\n",
    "\n",
    "Pour rappel, les valeurs de similarité sont comprises entre -1 et 1. Une valeur de 1 signifie que les deux vecteurs sont identiques, une valeur de -1 signifie qu'ils sont opposés, et une valeur de 0 signifie qu'ils sont orthogonaux (sans rapport l'un avec l'autre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.  Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés.  Pour chaque paire, calculez la similarité entre les deux mots.  Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre Lucas et Rémi est :  0.138594\n",
      "La similarité entre dog et cat est :  0.76094574\n",
      "La similarité entre rabbit et cat est :  0.6261382\n",
      "La similarité entre lettuce et judge est :  0.045975238\n",
      "La similarité entre pollution et Pollution est :  0.7395129\n"
     ]
    }
   ],
   "source": [
    "sim1 = w2v_vectors.similarity(\"Lucas\", \"Rémi\")\n",
    "sim2 = w2v_vectors.similarity(\"dog\", \"cat\")\n",
    "sim3 = w2v_vectors.similarity(\"rabbit\", \"cat\")\n",
    "sim4 = w2v_vectors.similarity(\"lettuce\", \"judge\")\n",
    "sim5 = w2v_vectors.similarity(\"pollution\", \"Pollution\")\n",
    "\n",
    "print(\"\\nLa similarité entre Lucas et Rémi est : \", sim1)\n",
    "print(\"La similarité entre dog et cat est : \", sim2)\n",
    "print(\"La similarité entre rabbit et cat est : \", sim3)\n",
    "print(\"La similarité entre lettuce et judge est : \", sim4)\n",
    "print(\"La similarité entre pollution et Pollution est : \", sim5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "Grâce aux tests ci-dessus, on peut voir qu'il est assez \"logique\" dans son fonctionnement. Globalement les mots de sens proches (ici dog, cat, rabbit) sont proches dans l'espace vectoriel et a l'inverse les mots éloignés (ici lettuce et judge) sont éloignés dans l'espace vectoriel.\n",
    "\n",
    "Aussi on peut voir que avec des prénoms (ici Lucas et Rémi) il n'est pas très bon.\n",
    "Chose intéressante aussi, un même mot mais avec une majuscule (ici \"pollution\" et \"Pollution\") n'est pas le même dans l'espace vectoriel. Cela montre que le modèle est sensible à la casse des lettres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f.  Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ?  Est-ce une qualité ou un défaut du modèle word2vec ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre Life et Death est :  0.36187768\n",
      "La similarité entre Happiness et Sadness est :  0.42666298\n"
     ]
    }
   ],
   "source": [
    "sim1 = w2v_vectors.similarity(\"life\", \"death\")\n",
    "sim2 = w2v_vectors.similarity(\"happiness\", \"sadness\")\n",
    "\n",
    "print(\"\\nLa similarité entre Life et Death est : \", sim1)\n",
    "print(\"La similarité entre Happiness et Sadness est : \", sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "Avec les exemples ci-dessus, on peut voir que le modèle dit que des mots opposés sont assez similaire. Cela s'explique par le fait que bien qu'il ont des sens opposés, ils sont souvent utilisés dans le même contexte ou représentent des concepts égaux. Par exemple \"Happiness\" et \"Sadness\" sont des émotions et sont donc \"proche\" dans ce sens.\n",
    "\n",
    "Cela peut être considéré comme un défaut du modèle, car il ne prend pas en compte le sens des mots, mais seulement leur contexte d'utilisation. Cela peut poser problème dans certaines situations où il est important de prendre en compte le sens des mots. Cependant, cela peut aussi être considéré comme une qualité, car cela permet de capturer des relations sémantiques plus larges entre les mots. Il est donc important de garder à l'esprit que le modèle word2vec n'est pas parfait et qu'il a ses limites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g.  En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353.  Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les scores du modèle word2vec sur les données de test WordSimilarity-353 sont : \n",
      "Pearson correlation: 0.6239 (p-value: 1.7963227018764578e-39)\n",
      "Spearman correlation: 0.6589 (p-value: 2.5346056459149263e-45)\n",
      "OOV ratio: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "wordsim353_sim = w2v_vectors.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "\n",
    "print(\"Les scores du modèle word2vec sur les données de test WordSimilarity-353 sont : \")\n",
    "\n",
    "print(f\"Pearson correlation: {wordsim353_sim[0][0]:.4f} (p-value: {wordsim353_sim[0][1]})\")\n",
    "print(f\"Spearman correlation: {wordsim353_sim[1][0]:.4f} (p-value: {wordsim353_sim[1][1]})\")\n",
    "print(f\"OOV ratio: {wordsim353_sim[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "\n",
    "- Corrélation de Pearson : Mesure la corrélation linéaire entre les similarités prédites par le modèle et les similarités \"humaines\" attendues. Toujours une valeur entre -1 et 1.\n",
    "- Corrélation de Spearman : Mesure la corrélation de rang (ordre relatif des similarités). Permet de savoir si les ***ordres*** des paires entre les deux datasets sont similaires.\n",
    "- Ratio OOV : Ce ratio correspond à la proportion de paires de mots où au moins l'un des deux mots est hors vocabulaire (Out-Of-Vocabulary). Ce ratio est important car il correspond à la proportion de paires que notre modèle ne peut pas traiter.\n",
    "\n",
    "#### h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données\n",
    "questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut\n",
    "mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières\n",
    "analogies). Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.7401448525607863\n"
     ]
    }
   ],
   "source": [
    "print(\"Score :\", analogy_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :* Le score du modèle sur les analogies est calculé en comparant les prédictions du modèle pour des analogies de type \"A est à B ce que C est à ???\". Le score correspond au pourcentage d'analogies correctement résolues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Entraîner deux nouveaux modèles word2vec à partir de deux corpus\n",
    "\n",
    "#### a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = api.load('text8'). Combien de phrases et de mots (tokens) possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "- Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "- Combien de temps prend l’entraînement sur le corpus total ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension des embeddings : 100\n",
      "Temps d'entraînement : 243.07 secondes\n",
      "Taille du modèle sauvegardé : 56.47 Mo\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "corpus = list(corpus)\n",
    "\n",
    "start_time = time.time()\n",
    "model = Word2Vec(\n",
    "    sentences=corpus,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "model.save(\"word2vec_text8.model\")\n",
    "\n",
    "model_size = os.path.getsize(\"word2vec_text8.model\") / (1024 * 1024)  # Mo\n",
    "\n",
    "print(f\"Dimension des embeddings : {model.vector_size}\")\n",
    "print(f\"Temps d'entraînement : {training_time:.2f} secondes\")\n",
    "print(f\"Taille du modèle sauvegardé : {model_size:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.6117 (p-value: 2.1155809428710026e-37)\n",
      "Spearman correlation: 0.6242 (p-value: 2.6301584031768622e-39)\n",
      "OOV ratio: 0.5666\n",
      "Score : 0.23251248106804287\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "wordsim353_sim = model.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "print(f\"Pearson correlation: {wordsim353_sim[0][0]:.4f} (p-value: {wordsim353_sim[0][1]})\")\n",
    "print(f\"Spearman correlation: {wordsim353_sim[1][0]:.4f} (p-value: {wordsim353_sim[1][1]})\")\n",
    "print(f\"OOV ratio: {wordsim353_sim[2]:.4f}\")\n",
    "\n",
    "analogy_scores = model.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(\"Score :\", analogy_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "\n",
    "Pour rappel, voici les scores obtenus avec le modèle pré-entrainé :\n",
    "\n",
    "- Pearson correlation: 0.6239 (p-value: 1.7963227018764578e-39)\n",
    "- Spearman correlation: 0.6589 (p-value: 2.5346056459149263e-45)\n",
    "- OOV ratio: 0.0000\n",
    "- Score d'analogie : 0.7401448525607863\n",
    "\n",
    "On obtient des scores légèrement moins bon au niveau de la similarité. Mais un score nettement plus mauvais (0.23 vs 0.74) pour les tests d'analogie. Cela est probablement du au fait que le corpus sur lequel nous avons entraîné notre modèle est bien plus petit que celui du modèle pré-entrainé. Il y a donc beaucoup de données d'exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters fourni par l’enseignant et appelé wikipedia_augmented.zip (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings.\n",
    "- Utilisez la classe Text8Corpus() pour charger ce corpus, ce qui fera automatiquement la\n",
    "tokenisation et la segmentation en phrases.\n",
    "- Combien de temps prend l’entraînement ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entraînement : 670.23 secondes\n",
      "Taille du modèle : 3.71 Mo\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "import time\n",
    "import os\n",
    "\n",
    "corpus_path = 'data/wikipedia_augmented.dat'\n",
    "sentences = Text8Corpus(corpus_path)\n",
    "\n",
    "start_time = time.time()\n",
    "model_large = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=5, workers=4)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "model_large.save(\"word2vec_large.model\")\n",
    "\n",
    "model_size = os.path.getsize(\"word2vec_large.model\") / (1024 * 1024)  # en Mo\n",
    "print(f\"Temps d'entraînement : {training_time:.2f} secondes\")\n",
    "print(f\"Taille du modèle : {model_size:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses :*\n",
    "\n",
    "- L'entraînement prend ~11 minutes\n",
    "- La taille du modèle entraîné est de 3.71 Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.5071 (p-value: 1.8383209172551684e-24)\n",
      "Spearman correlation: 0.5163 (p-value: 1.921153670703376e-25)\n",
      "OOV ratio: 0.0000\n",
      "Score : 0.3526212747443985\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wordsim353_sim = model_large.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "print(f\"Pearson correlation: {wordsim353_sim[0][0]:.4f} (p-value: {wordsim353_sim[0][1]})\")\n",
    "print(f\"Spearman correlation: {wordsim353_sim[1][0]:.4f} (p-value: {wordsim353_sim[1][1]})\")\n",
    "print(f\"OOV ratio: {wordsim353_sim[2]:.4f}\")\n",
    "\n",
    "analogy_scores = model_large.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(\"Score :\", analogy_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :* \n",
    "\n",
    "Voici un tableau récapitulant les scores obtenus pour chacun des modèles : le modèle pré-entraîné, le modèle sur le petit corpus, le modèle sur le corpus wikipedia :\n",
    "\n",
    "| Modèle              | Pearson corr. | Spearman corr. | OOV ratio | Analogy score          |\n",
    "|---------------------|---------------|----------------|-----------|------------------------|\n",
    "| Modèle pré-entraîné | 0.6239        | 0.6589         | 0.0000    | 0.7401                 |\n",
    "| Petit corpus        | 0.6117        | 0.6242         | 0.5666    | 0.2325                 |\n",
    "| Corpus Wikipedia    | 0.5071        | 0.5163         | 0.0000    | 0.3526                 |\n",
    "\n",
    "\n",
    "Ici le résultat obtenu est assez intéressant. Par rapport au premier dataset, on obtient de moins bons scores avec la corrélation de Pearson et de Spearman qu'avec le petit dataset. Le deuxième dataset est une extension du premier mais avec des données spécifiques en plus (dépêches économiques de Reuters). Les embeddings des mots ont donc été encodés pour correspondre à ce contexte spécifique, d'où la différence entre le modèle entraîné sur le petit corpus (moins biaisé) et ce deuxième modèle.\n",
    "Cela dit, le deuxième modèle obtient quand même un meilleur résultat sur le test d'analogies. \n",
    "\n",
    "On peut conclure que le ***volume*** et le ***contexte*** des données d'entraînement sont les deux caractéristiques les plus importantes lorsque nous souhaitons entraîner un modèle word2vec. Le contexte donnera de bons embeddings et un volume suffisant donnera de meilleurs scores aux tests d'analogies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
