{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 5<br/> Word2Vec\n",
    "\n",
    "## Rémi Ançay - Lucas Charbonnier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tester et évaluer un modèle déjà entraîné sur Google News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader as api\n",
    "\n",
    "# Save the word2vec model to a file\n",
    "#w2v_vectors = api.load(\"word2vec-google-news-300\")\n",
    "#w2v_vectors.save_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors \n",
    "# Load the word2vec model from the file\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.  Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :* \n",
    "Pour cela, il faut d'abord exécuter la cellule ci-dessous pour charger le modèle. Ensuite, on peut regarder grâce au gestionnaire de tâches de l'OS combien de place il occupe. On voit que le modèle pèse environ 4 Go de mémoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.  Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de l'espace vectoriel :  300\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension de l'espace vectoriel : \", w2v_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.  Quelle est la taille du vocabulaire connu du modèle ?  Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire: 3000000\n",
      "Quelques mots anglais dans le vocabulaire :  ['was', 'the', 'at', 'not', 'as']\n",
      "\n",
      "Test de mots dans le vocabulaire : \n",
      "False False\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille du vocabulaire:\", len(w2v_vectors.key_to_index))\n",
    "\n",
    "print(\"Quelques mots anglais dans le vocabulaire : \", list(w2v_vectors.key_to_index.keys())[10:15])\n",
    "\n",
    "print(\"\\nTest de mots dans le vocabulaire : \")\n",
    "print(\"Lucas123\" in w2v_vectors, \"Rémi456\" in w2v_vectors)\n",
    "print(\"Lucas\" in w2v_vectors, \"Rémi\" in w2v_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "On peut voir ici que les mots \"Lucas123\" et \"Rémi123\" ne sont pas dans le vocabulaire du modèle. En revanche, les mots \"Lucas\", \"Rémi\" y sont présents. (J'ai essayé avec d'autres mots compliqués, mais ils sont tous présents dans le vocabulaire du modèle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.  Quelle est la similarité entre les mots rabbit et carrot ?  Veuillez rappeler comment on mesure les \n",
    "similarités entre deux mots grâce à leurs vecteurs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre rabbit et carrot est :  0.36306435\n",
      "\n",
      "La similarité entre rabbit et cat est :  0.6261382\n"
     ]
    }
   ],
   "source": [
    "s1 = w2v_vectors.similarity(\"rabbit\", \"carrot\")\n",
    "print(\"\\nLa similarité entre rabbit et carrot est : \", s1)\n",
    "\n",
    "s2 = w2v_vectors.similarity(\"rabbit\", \"cat\")\n",
    "print(\"\\nLa similarité entre rabbit et cat est : \", s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "La similarité est mesurée grâce à la distance cosinus entre les deux vecteurs. On peut voir que la similarité entre \"rabbit\" et \"carrot\" est de 0.36. Cela signifie que ces deux mots sont assez proches l'un de l'autre dans l'espace vectoriel, mais pas trop. Par exemple entre \"rabbit\" et \"cat\", la similarité est de 0.62. Cela signifie que ces deux mots sont plus proches l'un de l'autre que \"rabbit\" et \"carrot\".\n",
    "\n",
    "La distance cosinus est calculée avec la formule suivante :\n",
    "$$\n",
    "\\text{similarity}(a, b) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}$$\n",
    "où $a$ et $b$ sont les vecteurs de mots, $||a||$ et $||b||$ sont les normes des vecteurs, et $a \\cdot b$ est le produit scalaire entre les deux vecteurs.\n",
    "\n",
    "Pour rappel, les valeurs de similarité sont comprises entre -1 et 1. Une valeur de 1 signifie que les deux vecteurs sont identiques, une valeur de -1 signifie qu'ils sont opposés, et une valeur de 0 signifie qu'ils sont orthogonaux (sans rapport l'un avec l'autre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.  Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés.  Pour chaque paire, calculez la similarité entre les deux mots.  Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre Lucas et Rémi est :  0.13859402\n",
      "La similarité entre dog et cat est :  0.76094574\n",
      "La similarité entre rabbit et cat est :  0.6261382\n",
      "La similarité entre lettuce et judge est :  0.04597524\n",
      "La similarité entre pollution et Pollution est :  0.7395129\n"
     ]
    }
   ],
   "source": [
    "sim1 = w2v_vectors.similarity(\"Lucas\", \"Rémi\")\n",
    "sim2 = w2v_vectors.similarity(\"dog\", \"cat\")\n",
    "sim3 = w2v_vectors.similarity(\"rabbit\", \"cat\")\n",
    "sim4 = w2v_vectors.similarity(\"lettuce\", \"judge\")\n",
    "sim5 = w2v_vectors.similarity(\"pollution\", \"Pollution\")\n",
    "\n",
    "print(\"\\nLa similarité entre Lucas et Rémi est : \", sim1)\n",
    "print(\"La similarité entre dog et cat est : \", sim2)\n",
    "print(\"La similarité entre rabbit et cat est : \", sim3)\n",
    "print(\"La similarité entre lettuce et judge est : \", sim4)\n",
    "print(\"La similarité entre pollution et Pollution est : \", sim5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "Grâce aux tests ci-dessus, on peut voir qu'il est assez \"logique\" dans son fonctionnement. Globalement les mots de sens proches (ici dog, cat, rabbit) sont proches dans l'espace vectoriel et a l'inverse les mots éloignés (ici lettuce et judge) sont éloignés dans l'espace vectoriel.\n",
    "\n",
    "Aussi on peut voir que avec des prénoms (ici Lucas et Rémi) il n'est pas très bon.\n",
    "Chose intéressante aussi, un même mot mais avec une majuscule (ici \"pollution\" et \"Pollution\") n'est pas le même dans l'espace vectoriel. Cela montre que le modèle est sensible à la casse des lettres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f.  Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ?  Est-ce une qualité ou un défaut du modèle word2vec ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La similarité entre Life et Death est :  0.33894566\n",
      "La similarité entre Happiness et Sadness est :  0.29912347\n"
     ]
    }
   ],
   "source": [
    "sim1 = w2v_vectors.similarity(\"Life\", \"Death\")\n",
    "sim2 = w2v_vectors.similarity(\"Happiness\", \"Sadness\")\n",
    "\n",
    "print(\"\\nLa similarité entre Life et Death est : \", sim1)\n",
    "print(\"La similarité entre Happiness et Sadness est : \", sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "Avec les exemples ci-dessus, on peut voir que le modèle dit que des mots opposés sont assez similaire. Cela s'explique par le fait que bien qu'il ont des sens opposés, ils sont souvent utilisés dans le même contexte ou représentent des concepts égaux. Par exemple \"Happiness\" et \"Sadness\" sont des émotions et sont donc \"proche\" dans ce sens.\n",
    "\n",
    "Cela peut être considéré comme un défaut du modèle, car il ne prend pas en compte le sens des mots, mais seulement leur contexte d'utilisation. Cela peut poser problème dans certaines situations où il est important de prendre en compte le sens des mots. Cependant, cela peut aussi être considéré comme une qualité, car cela permet de capturer des relations sémantiques plus larges entre les mots. Il est donc important de garder à l'esprit que le modèle word2vec n'est pas parfait et qu'il a ses limites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g.  En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353.  Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les scores du modèle word2vec sur les données de test WordSimilarity-353 sont : \n",
      "PearsonRResult(statistic=0.6238773466616101, pvalue=1.7963237724181868e-39)\n",
      "SignificanceResult(statistic=0.6589215888009288, pvalue=2.5346056459149263e-45)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "wordsim353_sim = w2v_vectors.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "\n",
    "print(\"Les scores du modèle word2vec sur les données de test WordSimilarity-353 sont : \")\n",
    "for score in wordsim353_sim:\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*\n",
    "TODO explication des scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
